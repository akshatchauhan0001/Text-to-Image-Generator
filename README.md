# Project 2 Text-to-Image-Generator
Text-to-Image Synthesis project represents a pioneering effort in bridging the gap between language and vision, offering a versatile and powerful tool for generating visual content from textual descriptions across various domains and applications.
This project implements an end-to-end pipeline for generating images from textual descriptions using the StableDiffusionPipeline. The pipeline leverages deep learning techniques to translate textual input into visually realistic images. The StableDiffusionPipeline is a state-of-the-art model architecture that utilizes diffusion models for high-quality image synthesis.

The United1.ipynb file contains the code that helps user to test the StableDiffusionPipeline model to generate images on basis of text given by the user dynamically.
(image.py file),As we are working on google colab notebook so streamlit is runned using (.py) files so the code is written in image.py which is runned using the united1.ipynb file by running the following commands streamlit run image.py and so on.


Requirements ->

Python (>= 3.6)
PyTorch (>= 1.9.0)
Hugging Face Transformers
TorchVision
numpy
matplotlib
PIL (Python Imaging Library)
tqdm
